# Autogenerated by onnx-pytorch.

import glob
import os
import math

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision


class Model(nn.Module):
  def __init__(self):
    super(Model, self).__init__()
    self._vars = nn.ParameterDict()
    self._regularizer_params = []
    for b in glob.glob(
        os.path.join(os.path.dirname(__file__), "variables", "*.npy")):
      v = torch.from_numpy(np.load(b))
      requires_grad = v.dtype.is_floating_point or v.dtype.is_complex
      self._vars[os.path.basename(b)[:-4]] = nn.Parameter(v, requires_grad=requires_grad)
    self.n_Conv_0 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 12, 'bias': True})
    self.n_Conv_0.weight.data = self._vars["onnx__Conv_1975"]
    self.n_Conv_0.bias.data = self._vars["onnx__Conv_1976"]
    self.n_Conv_2 = nn.Conv2d(**{'groups': 32, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_Conv_2.weight.data = self._vars["onnx__Conv_1978"]
    self.n_Conv_2.bias.data = self._vars["onnx__Conv_1979"]
    self.n_Conv_4 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_Conv_4.weight.data = self._vars["onnx__Conv_1981"]
    self.n_Conv_4.bias.data = self._vars["onnx__Conv_1982"]
    self.n_Conv_5 = nn.Conv2d(**{'groups': 16, 'dilation': [1, 1], 'out_channels': 16, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_Conv_5.weight.data = self._vars["onnx__Conv_1984"]
    self.n_Conv_5.bias.data = self._vars["onnx__Conv_1985"]
    self.n_Conv_7 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_Conv_7.weight.data = self._vars["onnx__Conv_1987"]
    self.n_Conv_7.bias.data = self._vars["onnx__Conv_1988"]
    self.n_Conv_9 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 96, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_Conv_9.weight.data = self._vars["onnx__Conv_1990"]
    self.n_Conv_9.bias.data = self._vars["onnx__Conv_1991"]
    self.n_Conv_11 = nn.Conv2d(**{'groups': 96, 'dilation': [1, 1], 'out_channels': 96, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 96, 'bias': True})
    self.n_Conv_11.weight.data = self._vars["onnx__Conv_1993"]
    self.n_Conv_11.bias.data = self._vars["onnx__Conv_1994"]
    self.n_Conv_13 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 24, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 96, 'bias': True})
    self.n_Conv_13.weight.data = self._vars["onnx__Conv_1996"]
    self.n_Conv_13.bias.data = self._vars["onnx__Conv_1997"]
    self.n_Conv_14 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 144, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 24, 'bias': True})
    self.n_Conv_14.weight.data = self._vars["onnx__Conv_1999"]
    self.n_Conv_14.bias.data = self._vars["onnx__Conv_2000"]
    self.n_Conv_16 = nn.Conv2d(**{'groups': 144, 'dilation': [1, 1], 'out_channels': 144, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_16.weight.data = self._vars["onnx__Conv_2002"]
    self.n_Conv_16.bias.data = self._vars["onnx__Conv_2003"]
    self.n_Conv_18 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 24, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_18.weight.data = self._vars["onnx__Conv_2005"]
    self.n_Conv_18.bias.data = self._vars["onnx__Conv_2006"]
    self.n_Conv_20 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 144, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 24, 'bias': True})
    self.n_Conv_20.weight.data = self._vars["onnx__Conv_2008"]
    self.n_Conv_20.bias.data = self._vars["onnx__Conv_2009"]
    self.n_Conv_22 = nn.Conv2d(**{'groups': 144, 'dilation': [1, 1], 'out_channels': 144, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_22.weight.data = self._vars["onnx__Conv_2011"]
    self.n_Conv_22.bias.data = self._vars["onnx__Conv_2012"]
    self.n_Conv_24 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 24, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_24.weight.data = self._vars["onnx__Conv_2014"]
    self.n_Conv_24.bias.data = self._vars["onnx__Conv_2015"]
    self.n_Conv_26 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 144, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 24, 'bias': True})
    self.n_Conv_26.weight.data = self._vars["onnx__Conv_2017"]
    self.n_Conv_26.bias.data = self._vars["onnx__Conv_2018"]
    self.n_Conv_28 = nn.Conv2d(**{'groups': 144, 'dilation': [1, 1], 'out_channels': 144, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [2, 2], 'in_channels': 144, 'bias': True})
    self.n_Conv_28.weight.data = self._vars["onnx__Conv_2020"]
    self.n_Conv_28.bias.data = self._vars["onnx__Conv_2021"]
    self.n_Conv_30 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 48, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_30.weight.data = self._vars["onnx__Conv_2023"]
    self.n_Conv_30.bias.data = self._vars["onnx__Conv_2024"]
    self.n_Conv_31 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 288, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 48, 'bias': True})
    self.n_Conv_31.weight.data = self._vars["onnx__Conv_2026"]
    self.n_Conv_31.bias.data = self._vars["onnx__Conv_2027"]
    self.n_Conv_33 = nn.Conv2d(**{'groups': 288, 'dilation': [1, 1], 'out_channels': 288, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 288, 'bias': True})
    self.n_Conv_33.weight.data = self._vars["onnx__Conv_2029"]
    self.n_Conv_33.bias.data = self._vars["onnx__Conv_2030"]
    self.n_Conv_35 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 48, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 288, 'bias': True})
    self.n_Conv_35.weight.data = self._vars["onnx__Conv_2032"]
    self.n_Conv_35.bias.data = self._vars["onnx__Conv_2033"]
    self.n_Conv_37 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 288, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 48, 'bias': True})
    self.n_Conv_37.weight.data = self._vars["onnx__Conv_2035"]
    self.n_Conv_37.bias.data = self._vars["onnx__Conv_2036"]
    self.n_Conv_39 = nn.Conv2d(**{'groups': 288, 'dilation': [1, 1], 'out_channels': 288, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 288, 'bias': True})
    self.n_Conv_39.weight.data = self._vars["onnx__Conv_2038"]
    self.n_Conv_39.bias.data = self._vars["onnx__Conv_2039"]
    self.n_Conv_41 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 48, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 288, 'bias': True})
    self.n_Conv_41.weight.data = self._vars["onnx__Conv_2041"]
    self.n_Conv_41.bias.data = self._vars["onnx__Conv_2042"]
    self.n_Conv_43 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 288, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 48, 'bias': True})
    self.n_Conv_43.weight.data = self._vars["onnx__Conv_2044"]
    self.n_Conv_43.bias.data = self._vars["onnx__Conv_2045"]
    self.n_Conv_45 = nn.Conv2d(**{'groups': 288, 'dilation': [1, 1], 'out_channels': 288, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 288, 'bias': True})
    self.n_Conv_45.weight.data = self._vars["onnx__Conv_2047"]
    self.n_Conv_45.bias.data = self._vars["onnx__Conv_2048"]
    self.n_Conv_47 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 88, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 288, 'bias': True})
    self.n_Conv_47.weight.data = self._vars["onnx__Conv_2050"]
    self.n_Conv_47.bias.data = self._vars["onnx__Conv_2051"]
    self.n_Conv_48 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 528, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 88, 'bias': True})
    self.n_Conv_48.weight.data = self._vars["onnx__Conv_2053"]
    self.n_Conv_48.bias.data = self._vars["onnx__Conv_2054"]
    self.n_Conv_50 = nn.Conv2d(**{'groups': 528, 'dilation': [1, 1], 'out_channels': 528, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_50.weight.data = self._vars["onnx__Conv_2056"]
    self.n_Conv_50.bias.data = self._vars["onnx__Conv_2057"]
    self.n_Conv_52 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 88, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_52.weight.data = self._vars["onnx__Conv_2059"]
    self.n_Conv_52.bias.data = self._vars["onnx__Conv_2060"]
    self.n_Conv_54 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 528, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 88, 'bias': True})
    self.n_Conv_54.weight.data = self._vars["onnx__Conv_2062"]
    self.n_Conv_54.bias.data = self._vars["onnx__Conv_2063"]
    self.n_Conv_56 = nn.Conv2d(**{'groups': 528, 'dilation': [1, 1], 'out_channels': 528, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_56.weight.data = self._vars["onnx__Conv_2065"]
    self.n_Conv_56.bias.data = self._vars["onnx__Conv_2066"]
    self.n_Conv_58 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 88, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_58.weight.data = self._vars["onnx__Conv_2068"]
    self.n_Conv_58.bias.data = self._vars["onnx__Conv_2069"]
    self.n_Conv_60 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 528, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 88, 'bias': True})
    self.n_Conv_60.weight.data = self._vars["onnx__Conv_2071"]
    self.n_Conv_60.bias.data = self._vars["onnx__Conv_2072"]
    self.n_Conv_62 = nn.Conv2d(**{'groups': 528, 'dilation': [1, 1], 'out_channels': 528, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_62.weight.data = self._vars["onnx__Conv_2074"]
    self.n_Conv_62.bias.data = self._vars["onnx__Conv_2075"]
    self.n_Conv_64 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 88, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_64.weight.data = self._vars["onnx__Conv_2077"]
    self.n_Conv_64.bias.data = self._vars["onnx__Conv_2078"]
    self.n_Conv_66 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 528, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 88, 'bias': True})
    self.n_Conv_66.weight.data = self._vars["onnx__Conv_2080"]
    self.n_Conv_66.bias.data = self._vars["onnx__Conv_2081"]
    self.n_Conv_68 = nn.Conv2d(**{'groups': 528, 'dilation': [1, 1], 'out_channels': 528, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_68.weight.data = self._vars["onnx__Conv_2083"]
    self.n_Conv_68.bias.data = self._vars["onnx__Conv_2084"]
    self.n_Conv_70 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 120, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 528, 'bias': True})
    self.n_Conv_70.weight.data = self._vars["onnx__Conv_2086"]
    self.n_Conv_70.bias.data = self._vars["onnx__Conv_2087"]
    self.n_Conv_71 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 720, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 120, 'bias': True})
    self.n_Conv_71.weight.data = self._vars["onnx__Conv_2089"]
    self.n_Conv_71.bias.data = self._vars["onnx__Conv_2090"]
    self.n_Conv_73 = nn.Conv2d(**{'groups': 720, 'dilation': [1, 1], 'out_channels': 720, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_73.weight.data = self._vars["onnx__Conv_2092"]
    self.n_Conv_73.bias.data = self._vars["onnx__Conv_2093"]
    self.n_Conv_75 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 120, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_75.weight.data = self._vars["onnx__Conv_2095"]
    self.n_Conv_75.bias.data = self._vars["onnx__Conv_2096"]
    self.n_Conv_77 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 720, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 120, 'bias': True})
    self.n_Conv_77.weight.data = self._vars["onnx__Conv_2098"]
    self.n_Conv_77.bias.data = self._vars["onnx__Conv_2099"]
    self.n_Conv_79 = nn.Conv2d(**{'groups': 720, 'dilation': [1, 1], 'out_channels': 720, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_79.weight.data = self._vars["onnx__Conv_2101"]
    self.n_Conv_79.bias.data = self._vars["onnx__Conv_2102"]
    self.n_Conv_81 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 120, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_81.weight.data = self._vars["onnx__Conv_2104"]
    self.n_Conv_81.bias.data = self._vars["onnx__Conv_2105"]
    self.n_Conv_83 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 720, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 120, 'bias': True})
    self.n_Conv_83.weight.data = self._vars["onnx__Conv_2107"]
    self.n_Conv_83.bias.data = self._vars["onnx__Conv_2108"]
    self.n_Conv_85 = nn.Conv2d(**{'groups': 720, 'dilation': [1, 1], 'out_channels': 720, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_85.weight.data = self._vars["onnx__Conv_2110"]
    self.n_Conv_85.bias.data = self._vars["onnx__Conv_2111"]
    self.n_Conv_87 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 120, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_87.weight.data = self._vars["onnx__Conv_2113"]
    self.n_Conv_87.bias.data = self._vars["onnx__Conv_2114"]
    self.n_Conv_89 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 720, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 120, 'bias': True})
    self.n_Conv_89.weight.data = self._vars["onnx__Conv_2116"]
    self.n_Conv_89.bias.data = self._vars["onnx__Conv_2117"]
    self.n_Conv_91 = nn.Conv2d(**{'groups': 720, 'dilation': [1, 1], 'out_channels': 720, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [2, 2], 'in_channels': 720, 'bias': True})
    self.n_Conv_91.weight.data = self._vars["onnx__Conv_2119"]
    self.n_Conv_91.bias.data = self._vars["onnx__Conv_2120"]
    self.n_Conv_93 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 208, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 720, 'bias': True})
    self.n_Conv_93.weight.data = self._vars["onnx__Conv_2122"]
    self.n_Conv_93.bias.data = self._vars["onnx__Conv_2123"]
    self.n_Conv_94 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 208, 'bias': True})
    self.n_Conv_94.weight.data = self._vars["onnx__Conv_2125"]
    self.n_Conv_94.bias.data = self._vars["onnx__Conv_2126"]
    self.n_Conv_96 = nn.Conv2d(**{'groups': 1248, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_96.weight.data = self._vars["onnx__Conv_2128"]
    self.n_Conv_96.bias.data = self._vars["onnx__Conv_2129"]
    self.n_Conv_98 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 208, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_98.weight.data = self._vars["onnx__Conv_2131"]
    self.n_Conv_98.bias.data = self._vars["onnx__Conv_2132"]
    self.n_Conv_100 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 208, 'bias': True})
    self.n_Conv_100.weight.data = self._vars["onnx__Conv_2134"]
    self.n_Conv_100.bias.data = self._vars["onnx__Conv_2135"]
    self.n_Conv_102 = nn.Conv2d(**{'groups': 1248, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_102.weight.data = self._vars["onnx__Conv_2137"]
    self.n_Conv_102.bias.data = self._vars["onnx__Conv_2138"]
    self.n_Conv_104 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 208, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_104.weight.data = self._vars["onnx__Conv_2140"]
    self.n_Conv_104.bias.data = self._vars["onnx__Conv_2141"]
    self.n_Conv_106 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 208, 'bias': True})
    self.n_Conv_106.weight.data = self._vars["onnx__Conv_2143"]
    self.n_Conv_106.bias.data = self._vars["onnx__Conv_2144"]
    self.n_Conv_108 = nn.Conv2d(**{'groups': 1248, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_108.weight.data = self._vars["onnx__Conv_2146"]
    self.n_Conv_108.bias.data = self._vars["onnx__Conv_2147"]
    self.n_Conv_110 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 208, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_110.weight.data = self._vars["onnx__Conv_2149"]
    self.n_Conv_110.bias.data = self._vars["onnx__Conv_2150"]
    self.n_Conv_112 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 208, 'bias': True})
    self.n_Conv_112.weight.data = self._vars["onnx__Conv_2152"]
    self.n_Conv_112.bias.data = self._vars["onnx__Conv_2153"]
    self.n_Conv_114 = nn.Conv2d(**{'groups': 1248, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_114.weight.data = self._vars["onnx__Conv_2155"]
    self.n_Conv_114.bias.data = self._vars["onnx__Conv_2156"]
    self.n_Conv_116 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 208, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_116.weight.data = self._vars["onnx__Conv_2158"]
    self.n_Conv_116.bias.data = self._vars["onnx__Conv_2159"]
    self.n_Conv_118 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 208, 'bias': True})
    self.n_Conv_118.weight.data = self._vars["onnx__Conv_2161"]
    self.n_Conv_118.bias.data = self._vars["onnx__Conv_2162"]
    self.n_Conv_120 = nn.Conv2d(**{'groups': 1248, 'dilation': [1, 1], 'out_channels': 1248, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_120.weight.data = self._vars["onnx__Conv_2164"]
    self.n_Conv_120.bias.data = self._vars["onnx__Conv_2165"]
    self.n_Conv_122 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 352, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1248, 'bias': True})
    self.n_Conv_122.weight.data = self._vars["onnx__Conv_2167"]
    self.n_Conv_122.bias.data = self._vars["onnx__Conv_2168"]
    self.n_Conv_123 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 2112, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 352, 'bias': True})
    self.n_Conv_123.weight.data = self._vars["onnx__Conv_2170"]
    self.n_Conv_123.bias.data = self._vars["onnx__Conv_2171"]
    self.n_Conv_125 = nn.Conv2d(**{'groups': 2112, 'dilation': [1, 1], 'out_channels': 2112, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 2112, 'bias': True})
    self.n_Conv_125.weight.data = self._vars["onnx__Conv_2173"]
    self.n_Conv_125.bias.data = self._vars["onnx__Conv_2174"]
    self.n_Conv_127 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 352, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 2112, 'bias': True})
    self.n_Conv_127.weight.data = self._vars["onnx__Conv_2176"]
    self.n_Conv_127.bias.data = self._vars["onnx__Conv_2177"]
    self.n_Conv_129 = nn.Conv2d(**{'groups': 352, 'dilation': [1, 1], 'out_channels': 352, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 352, 'bias': True})
    self.n_Conv_129.weight.data = self._vars["onnx__Conv_2179"]
    self.n_Conv_129.bias.data = self._vars["onnx__Conv_2180"]
    self.n_Conv_131 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 352, 'bias': True})
    self.n_Conv_131.weight.data = self._vars["onnx__Conv_2182"]
    self.n_Conv_131.bias.data = self._vars["onnx__Conv_2183"]
    self.n_Flatten_132 = nn.Flatten(**{'start_dim': 1})
    self.n_Conv_133 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 12, 'bias': True})
    self.n_Conv_133.weight.data = self._vars["onnx__Conv_2185"]
    self.n_Conv_133.bias.data = self._vars["onnx__Conv_2186"]
    self.n_Conv_135 = nn.Conv2d(**{'groups': 32, 'dilation': [1, 1], 'out_channels': 32, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_Conv_135.weight.data = self._vars["onnx__Conv_2188"]
    self.n_Conv_135.bias.data = self._vars["onnx__Conv_2189"]
    self.n_Conv_137 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 16, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 32, 'bias': True})
    self.n_Conv_137.weight.data = self._vars["onnx__Conv_2191"]
    self.n_Conv_137.bias.data = self._vars["onnx__Conv_2192"]
    self.n_Conv_138 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 96, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 16, 'bias': True})
    self.n_Conv_138.weight.data = self._vars["onnx__Conv_2194"]
    self.n_Conv_138.bias.data = self._vars["onnx__Conv_2195"]
    self.n_Conv_140 = nn.Conv2d(**{'groups': 96, 'dilation': [1, 1], 'out_channels': 96, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 96, 'bias': True})
    self.n_Conv_140.weight.data = self._vars["onnx__Conv_2197"]
    self.n_Conv_140.bias.data = self._vars["onnx__Conv_2198"]
    self.n_Conv_142 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 24, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 96, 'bias': True})
    self.n_Conv_142.weight.data = self._vars["onnx__Conv_2200"]
    self.n_Conv_142.bias.data = self._vars["onnx__Conv_2201"]
    self.n_Conv_143 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 144, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 24, 'bias': True})
    self.n_Conv_143.weight.data = self._vars["onnx__Conv_2203"]
    self.n_Conv_143.bias.data = self._vars["onnx__Conv_2204"]
    self.n_Conv_145 = nn.Conv2d(**{'groups': 144, 'dilation': [1, 1], 'out_channels': 144, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_145.weight.data = self._vars["onnx__Conv_2206"]
    self.n_Conv_145.bias.data = self._vars["onnx__Conv_2207"]
    self.n_Conv_147 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 24, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_147.weight.data = self._vars["onnx__Conv_2209"]
    self.n_Conv_147.bias.data = self._vars["onnx__Conv_2210"]
    self.n_Conv_149 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 144, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 24, 'bias': True})
    self.n_Conv_149.weight.data = self._vars["onnx__Conv_2212"]
    self.n_Conv_149.bias.data = self._vars["onnx__Conv_2213"]
    self.n_Conv_151 = nn.Conv2d(**{'groups': 144, 'dilation': [1, 1], 'out_channels': 144, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [2, 2], 'in_channels': 144, 'bias': True})
    self.n_Conv_151.weight.data = self._vars["onnx__Conv_2215"]
    self.n_Conv_151.bias.data = self._vars["onnx__Conv_2216"]
    self.n_Conv_153 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 40, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 144, 'bias': True})
    self.n_Conv_153.weight.data = self._vars["onnx__Conv_2218"]
    self.n_Conv_153.bias.data = self._vars["onnx__Conv_2219"]
    self.n_Conv_154 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 240, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 40, 'bias': True})
    self.n_Conv_154.weight.data = self._vars["onnx__Conv_2221"]
    self.n_Conv_154.bias.data = self._vars["onnx__Conv_2222"]
    self.n_Conv_156 = nn.Conv2d(**{'groups': 240, 'dilation': [1, 1], 'out_channels': 240, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 240, 'bias': True})
    self.n_Conv_156.weight.data = self._vars["onnx__Conv_2224"]
    self.n_Conv_156.bias.data = self._vars["onnx__Conv_2225"]
    self.n_Conv_158 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 40, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 240, 'bias': True})
    self.n_Conv_158.weight.data = self._vars["onnx__Conv_2227"]
    self.n_Conv_158.bias.data = self._vars["onnx__Conv_2228"]
    self.n_Conv_160 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 240, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 40, 'bias': True})
    self.n_Conv_160.weight.data = self._vars["onnx__Conv_2230"]
    self.n_Conv_160.bias.data = self._vars["onnx__Conv_2231"]
    self.n_Conv_162 = nn.Conv2d(**{'groups': 240, 'dilation': [1, 1], 'out_channels': 240, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 240, 'bias': True})
    self.n_Conv_162.weight.data = self._vars["onnx__Conv_2233"]
    self.n_Conv_162.bias.data = self._vars["onnx__Conv_2234"]
    self.n_Conv_164 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 80, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 240, 'bias': True})
    self.n_Conv_164.weight.data = self._vars["onnx__Conv_2236"]
    self.n_Conv_164.bias.data = self._vars["onnx__Conv_2237"]
    self.n_Conv_165 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 480, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 80, 'bias': True})
    self.n_Conv_165.weight.data = self._vars["onnx__Conv_2239"]
    self.n_Conv_165.bias.data = self._vars["onnx__Conv_2240"]
    self.n_Conv_167 = nn.Conv2d(**{'groups': 480, 'dilation': [1, 1], 'out_channels': 480, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 480, 'bias': True})
    self.n_Conv_167.weight.data = self._vars["onnx__Conv_2242"]
    self.n_Conv_167.bias.data = self._vars["onnx__Conv_2243"]
    self.n_Conv_169 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 80, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 480, 'bias': True})
    self.n_Conv_169.weight.data = self._vars["onnx__Conv_2245"]
    self.n_Conv_169.bias.data = self._vars["onnx__Conv_2246"]
    self.n_Conv_171 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 480, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 80, 'bias': True})
    self.n_Conv_171.weight.data = self._vars["onnx__Conv_2248"]
    self.n_Conv_171.bias.data = self._vars["onnx__Conv_2249"]
    self.n_Conv_173 = nn.Conv2d(**{'groups': 480, 'dilation': [1, 1], 'out_channels': 480, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 480, 'bias': True})
    self.n_Conv_173.weight.data = self._vars["onnx__Conv_2251"]
    self.n_Conv_173.bias.data = self._vars["onnx__Conv_2252"]
    self.n_Conv_175 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 80, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 480, 'bias': True})
    self.n_Conv_175.weight.data = self._vars["onnx__Conv_2254"]
    self.n_Conv_175.bias.data = self._vars["onnx__Conv_2255"]
    self.n_Conv_177 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 480, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 80, 'bias': True})
    self.n_Conv_177.weight.data = self._vars["onnx__Conv_2257"]
    self.n_Conv_177.bias.data = self._vars["onnx__Conv_2258"]
    self.n_Conv_179 = nn.Conv2d(**{'groups': 480, 'dilation': [1, 1], 'out_channels': 480, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 480, 'bias': True})
    self.n_Conv_179.weight.data = self._vars["onnx__Conv_2260"]
    self.n_Conv_179.bias.data = self._vars["onnx__Conv_2261"]
    self.n_Conv_181 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 112, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 480, 'bias': True})
    self.n_Conv_181.weight.data = self._vars["onnx__Conv_2263"]
    self.n_Conv_181.bias.data = self._vars["onnx__Conv_2264"]
    self.n_Conv_182 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 672, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 112, 'bias': True})
    self.n_Conv_182.weight.data = self._vars["onnx__Conv_2266"]
    self.n_Conv_182.bias.data = self._vars["onnx__Conv_2267"]
    self.n_Conv_184 = nn.Conv2d(**{'groups': 672, 'dilation': [1, 1], 'out_channels': 672, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 672, 'bias': True})
    self.n_Conv_184.weight.data = self._vars["onnx__Conv_2269"]
    self.n_Conv_184.bias.data = self._vars["onnx__Conv_2270"]
    self.n_Conv_186 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 112, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 672, 'bias': True})
    self.n_Conv_186.weight.data = self._vars["onnx__Conv_2272"]
    self.n_Conv_186.bias.data = self._vars["onnx__Conv_2273"]
    self.n_Conv_188 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 672, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 112, 'bias': True})
    self.n_Conv_188.weight.data = self._vars["onnx__Conv_2275"]
    self.n_Conv_188.bias.data = self._vars["onnx__Conv_2276"]
    self.n_Conv_190 = nn.Conv2d(**{'groups': 672, 'dilation': [1, 1], 'out_channels': 672, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 672, 'bias': True})
    self.n_Conv_190.weight.data = self._vars["onnx__Conv_2278"]
    self.n_Conv_190.bias.data = self._vars["onnx__Conv_2279"]
    self.n_Conv_192 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 112, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 672, 'bias': True})
    self.n_Conv_192.weight.data = self._vars["onnx__Conv_2281"]
    self.n_Conv_192.bias.data = self._vars["onnx__Conv_2282"]
    self.n_Conv_194 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 672, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 112, 'bias': True})
    self.n_Conv_194.weight.data = self._vars["onnx__Conv_2284"]
    self.n_Conv_194.bias.data = self._vars["onnx__Conv_2285"]
    self.n_Conv_196 = nn.Conv2d(**{'groups': 672, 'dilation': [1, 1], 'out_channels': 672, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [2, 2], 'in_channels': 672, 'bias': True})
    self.n_Conv_196.weight.data = self._vars["onnx__Conv_2287"]
    self.n_Conv_196.bias.data = self._vars["onnx__Conv_2288"]
    self.n_Conv_198 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 192, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 672, 'bias': True})
    self.n_Conv_198.weight.data = self._vars["onnx__Conv_2290"]
    self.n_Conv_198.bias.data = self._vars["onnx__Conv_2291"]
    self.n_Conv_199 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 192, 'bias': True})
    self.n_Conv_199.weight.data = self._vars["onnx__Conv_2293"]
    self.n_Conv_199.bias.data = self._vars["onnx__Conv_2294"]
    self.n_Conv_201 = nn.Conv2d(**{'groups': 1152, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_201.weight.data = self._vars["onnx__Conv_2296"]
    self.n_Conv_201.bias.data = self._vars["onnx__Conv_2297"]
    self.n_Conv_203 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 192, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_203.weight.data = self._vars["onnx__Conv_2299"]
    self.n_Conv_203.bias.data = self._vars["onnx__Conv_2300"]
    self.n_Conv_205 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 192, 'bias': True})
    self.n_Conv_205.weight.data = self._vars["onnx__Conv_2302"]
    self.n_Conv_205.bias.data = self._vars["onnx__Conv_2303"]
    self.n_Conv_207 = nn.Conv2d(**{'groups': 1152, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_207.weight.data = self._vars["onnx__Conv_2305"]
    self.n_Conv_207.bias.data = self._vars["onnx__Conv_2306"]
    self.n_Conv_209 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 192, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_209.weight.data = self._vars["onnx__Conv_2308"]
    self.n_Conv_209.bias.data = self._vars["onnx__Conv_2309"]
    self.n_Conv_211 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 192, 'bias': True})
    self.n_Conv_211.weight.data = self._vars["onnx__Conv_2311"]
    self.n_Conv_211.bias.data = self._vars["onnx__Conv_2312"]
    self.n_Conv_213 = nn.Conv2d(**{'groups': 1152, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [2, 2], 'kernel_size': (5, 5), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_213.weight.data = self._vars["onnx__Conv_2314"]
    self.n_Conv_213.bias.data = self._vars["onnx__Conv_2315"]
    self.n_Conv_215 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 192, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_215.weight.data = self._vars["onnx__Conv_2317"]
    self.n_Conv_215.bias.data = self._vars["onnx__Conv_2318"]
    self.n_Conv_217 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 192, 'bias': True})
    self.n_Conv_217.weight.data = self._vars["onnx__Conv_2320"]
    self.n_Conv_217.bias.data = self._vars["onnx__Conv_2321"]
    self.n_Conv_219 = nn.Conv2d(**{'groups': 1152, 'dilation': [1, 1], 'out_channels': 1152, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_219.weight.data = self._vars["onnx__Conv_2323"]
    self.n_Conv_219.bias.data = self._vars["onnx__Conv_2324"]
    self.n_Conv_221 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 320, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 1152, 'bias': True})
    self.n_Conv_221.weight.data = self._vars["onnx__Conv_2326"]
    self.n_Conv_221.bias.data = self._vars["onnx__Conv_2327"]
    self.n_Conv_222 = nn.Conv2d(**{'groups': 320, 'dilation': [1, 1], 'out_channels': 320, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 320, 'bias': True})
    self.n_Conv_222.weight.data = self._vars["onnx__Conv_2329"]
    self.n_Conv_222.bias.data = self._vars["onnx__Conv_2330"]
    self.n_Conv_224 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 32, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [1, 1], 'in_channels': 320, 'bias': True})
    self.n_Conv_224.weight.data = self._vars["onnx__Conv_2332"]
    self.n_Conv_224.bias.data = self._vars["onnx__Conv_2333"]
    self.n_Flatten_225 = nn.Flatten(**{'start_dim': 1})

  def forward(self, *inputs):
    input_imgs, big_input_imgs, desire, traffic_convention, initial_state = inputs
    input = self.n_Conv_0(input_imgs)
    onnx__Conv_1029 = F.elu(input)
    input_4 = self.n_Conv_2(onnx__Conv_1029)
    onnx__Conv_1036 = F.elu(input_4)
    input_8 = self.n_Conv_4(onnx__Conv_1036)
    input_12 = self.n_Conv_5(input_8)
    onnx__Conv_1049 = F.elu(input_12)
    onnx__Add_1986 = self.n_Conv_7(onnx__Conv_1049)
    input_16 = torch.add(onnx__Add_1986, input_8)
    input_20 = self.n_Conv_9(input_16)
    onnx__Conv_1063 = F.elu(input_20)
    input_24 = self.n_Conv_11(onnx__Conv_1063)
    onnx__Conv_1070 = F.elu(input_24)
    input_28 = self.n_Conv_13(onnx__Conv_1070)
    input_32 = self.n_Conv_14(input_28)
    onnx__Conv_1083 = F.elu(input_32)
    input_36 = self.n_Conv_16(onnx__Conv_1083)
    onnx__Conv_1090 = F.elu(input_36)
    onnx__Add_2004 = self.n_Conv_18(onnx__Conv_1090)
    input_40 = torch.add(onnx__Add_2004, input_28)
    input_44 = self.n_Conv_20(input_40)
    onnx__Conv_1104 = F.elu(input_44)
    input_48 = self.n_Conv_22(onnx__Conv_1104)
    onnx__Conv_1111 = F.elu(input_48)
    onnx__Add_2013 = self.n_Conv_24(onnx__Conv_1111)
    input_52 = torch.add(onnx__Add_2013, input_40)
    input_56 = self.n_Conv_26(input_52)
    onnx__Conv_1125 = F.elu(input_56)
    input_60 = self.n_Conv_28(onnx__Conv_1125)
    onnx__Conv_1132 = F.elu(input_60)
    input_64 = self.n_Conv_30(onnx__Conv_1132)
    input_68 = self.n_Conv_31(input_64)
    onnx__Conv_1145 = F.elu(input_68)
    input_72 = self.n_Conv_33(onnx__Conv_1145)
    onnx__Conv_1152 = F.elu(input_72)
    onnx__Add_2031 = self.n_Conv_35(onnx__Conv_1152)
    input_76 = torch.add(onnx__Add_2031, input_64)
    input_80 = self.n_Conv_37(input_76)
    onnx__Conv_1166 = F.elu(input_80)
    input_84 = self.n_Conv_39(onnx__Conv_1166)
    onnx__Conv_1173 = F.elu(input_84)
    onnx__Add_2040 = self.n_Conv_41(onnx__Conv_1173)
    input_88 = torch.add(onnx__Add_2040, input_76)
    input_92 = self.n_Conv_43(input_88)
    onnx__Conv_1187 = F.elu(input_92)
    input_96 = self.n_Conv_45(onnx__Conv_1187)
    onnx__Conv_1194 = F.elu(input_96)
    input_100 = self.n_Conv_47(onnx__Conv_1194)
    input_104 = self.n_Conv_48(input_100)
    onnx__Conv_1207 = F.elu(input_104)
    input_108 = self.n_Conv_50(onnx__Conv_1207)
    onnx__Conv_1214 = F.elu(input_108)
    onnx__Add_2058 = self.n_Conv_52(onnx__Conv_1214)
    input_112 = torch.add(onnx__Add_2058, input_100)
    input_116 = self.n_Conv_54(input_112)
    onnx__Conv_1228 = F.elu(input_116)
    input_120 = self.n_Conv_56(onnx__Conv_1228)
    onnx__Conv_1235 = F.elu(input_120)
    onnx__Add_2067 = self.n_Conv_58(onnx__Conv_1235)
    input_124 = torch.add(onnx__Add_2067, input_112)
    input_128 = self.n_Conv_60(input_124)
    onnx__Conv_1249 = F.elu(input_128)
    input_132 = self.n_Conv_62(onnx__Conv_1249)
    onnx__Conv_1256 = F.elu(input_132)
    onnx__Add_2076 = self.n_Conv_64(onnx__Conv_1256)
    input_136 = torch.add(onnx__Add_2076, input_124)
    input_140 = self.n_Conv_66(input_136)
    onnx__Conv_1270 = F.elu(input_140)
    input_144 = self.n_Conv_68(onnx__Conv_1270)
    onnx__Conv_1277 = F.elu(input_144)
    input_148 = self.n_Conv_70(onnx__Conv_1277)
    input_152 = self.n_Conv_71(input_148)
    onnx__Conv_1290 = F.elu(input_152)
    input_156 = self.n_Conv_73(onnx__Conv_1290)
    onnx__Conv_1297 = F.elu(input_156)
    onnx__Add_2094 = self.n_Conv_75(onnx__Conv_1297)
    input_160 = torch.add(onnx__Add_2094, input_148)
    input_164 = self.n_Conv_77(input_160)
    onnx__Conv_1311 = F.elu(input_164)
    input_168 = self.n_Conv_79(onnx__Conv_1311)
    onnx__Conv_1318 = F.elu(input_168)
    onnx__Add_2103 = self.n_Conv_81(onnx__Conv_1318)
    input_172 = torch.add(onnx__Add_2103, input_160)
    input_176 = self.n_Conv_83(input_172)
    onnx__Conv_1332 = F.elu(input_176)
    input_180 = self.n_Conv_85(onnx__Conv_1332)
    onnx__Conv_1339 = F.elu(input_180)
    onnx__Add_2112 = self.n_Conv_87(onnx__Conv_1339)
    input_184 = torch.add(onnx__Add_2112, input_172)
    input_188 = self.n_Conv_89(input_184)
    onnx__Conv_1353 = F.elu(input_188)
    input_192 = self.n_Conv_91(onnx__Conv_1353)
    onnx__Conv_1360 = F.elu(input_192)
    input_196 = self.n_Conv_93(onnx__Conv_1360)
    input_200 = self.n_Conv_94(input_196)
    onnx__Conv_1373 = F.elu(input_200)
    input_204 = self.n_Conv_96(onnx__Conv_1373)
    onnx__Conv_1380 = F.elu(input_204)
    onnx__Add_2130 = self.n_Conv_98(onnx__Conv_1380)
    input_208 = torch.add(onnx__Add_2130, input_196)
    input_212 = self.n_Conv_100(input_208)
    onnx__Conv_1394 = F.elu(input_212)
    input_216 = self.n_Conv_102(onnx__Conv_1394)
    onnx__Conv_1401 = F.elu(input_216)
    onnx__Add_2139 = self.n_Conv_104(onnx__Conv_1401)
    input_220 = torch.add(onnx__Add_2139, input_208)
    input_224 = self.n_Conv_106(input_220)
    onnx__Conv_1415 = F.elu(input_224)
    input_228 = self.n_Conv_108(onnx__Conv_1415)
    onnx__Conv_1422 = F.elu(input_228)
    onnx__Add_2148 = self.n_Conv_110(onnx__Conv_1422)
    input_232 = torch.add(onnx__Add_2148, input_220)
    input_236 = self.n_Conv_112(input_232)
    onnx__Conv_1436 = F.elu(input_236)
    input_240 = self.n_Conv_114(onnx__Conv_1436)
    onnx__Conv_1443 = F.elu(input_240)
    onnx__Add_2157 = self.n_Conv_116(onnx__Conv_1443)
    input_244 = torch.add(onnx__Add_2157, input_232)
    input_248 = self.n_Conv_118(input_244)
    onnx__Conv_1457 = F.elu(input_248)
    input_252 = self.n_Conv_120(onnx__Conv_1457)
    onnx__Conv_1464 = F.elu(input_252)
    input_256 = self.n_Conv_122(onnx__Conv_1464)
    input_260 = self.n_Conv_123(input_256)
    onnx__Conv_1477 = F.elu(input_260)
    input_264 = self.n_Conv_125(onnx__Conv_1477)
    onnx__Conv_1484 = F.elu(input_264)
    onnx__Add_2175 = self.n_Conv_127(onnx__Conv_1484)
    input_268 = torch.add(onnx__Add_2175, input_256)
    input_272 = self.n_Conv_129(input_268)
    onnx__Conv_1498 = F.elu(input_272)
    onnx__Flatten_2181 = self.n_Conv_131(onnx__Conv_1498)
    input_276 = self.n_Flatten_132(onnx__Flatten_2181)
    input_280 = self.n_Conv_133(big_input_imgs)
    onnx__Conv_1512 = F.elu(input_280)
    input_284 = self.n_Conv_135(onnx__Conv_1512)
    onnx__Conv_1519 = F.elu(input_284)
    input_288 = self.n_Conv_137(onnx__Conv_1519)
    input_292 = self.n_Conv_138(input_288)
    onnx__Conv_1532 = F.elu(input_292)
    input_296 = self.n_Conv_140(onnx__Conv_1532)
    onnx__Conv_1539 = F.elu(input_296)
    input_300 = self.n_Conv_142(onnx__Conv_1539)
    input_304 = self.n_Conv_143(input_300)
    onnx__Conv_1552 = F.elu(input_304)
    input_308 = self.n_Conv_145(onnx__Conv_1552)
    onnx__Conv_1559 = F.elu(input_308)
    onnx__Add_2208 = self.n_Conv_147(onnx__Conv_1559)
    input_312 = torch.add(onnx__Add_2208, input_300)
    input_316 = self.n_Conv_149(input_312)
    onnx__Conv_1573 = F.elu(input_316)
    input_320 = self.n_Conv_151(onnx__Conv_1573)
    onnx__Conv_1580 = F.elu(input_320)
    input_324 = self.n_Conv_153(onnx__Conv_1580)
    input_328 = self.n_Conv_154(input_324)
    onnx__Conv_1593 = F.elu(input_328)
    input_332 = self.n_Conv_156(onnx__Conv_1593)
    onnx__Conv_1600 = F.elu(input_332)
    onnx__Add_2226 = self.n_Conv_158(onnx__Conv_1600)
    input_336 = torch.add(onnx__Add_2226, input_324)
    input_340 = self.n_Conv_160(input_336)
    onnx__Conv_1614 = F.elu(input_340)
    input_344 = self.n_Conv_162(onnx__Conv_1614)
    onnx__Conv_1621 = F.elu(input_344)
    input_348 = self.n_Conv_164(onnx__Conv_1621)
    input_352 = self.n_Conv_165(input_348)
    onnx__Conv_1634 = F.elu(input_352)
    input_356 = self.n_Conv_167(onnx__Conv_1634)
    onnx__Conv_1641 = F.elu(input_356)
    onnx__Add_2244 = self.n_Conv_169(onnx__Conv_1641)
    input_360 = torch.add(onnx__Add_2244, input_348)
    input_364 = self.n_Conv_171(input_360)
    onnx__Conv_1655 = F.elu(input_364)
    input_368 = self.n_Conv_173(onnx__Conv_1655)
    onnx__Conv_1662 = F.elu(input_368)
    onnx__Add_2253 = self.n_Conv_175(onnx__Conv_1662)
    input_372 = torch.add(onnx__Add_2253, input_360)
    input_376 = self.n_Conv_177(input_372)
    onnx__Conv_1676 = F.elu(input_376)
    input_380 = self.n_Conv_179(onnx__Conv_1676)
    onnx__Conv_1683 = F.elu(input_380)
    input_384 = self.n_Conv_181(onnx__Conv_1683)
    input_388 = self.n_Conv_182(input_384)
    onnx__Conv_1696 = F.elu(input_388)
    input_392 = self.n_Conv_184(onnx__Conv_1696)
    onnx__Conv_1703 = F.elu(input_392)
    onnx__Add_2271 = self.n_Conv_186(onnx__Conv_1703)
    input_396 = torch.add(onnx__Add_2271, input_384)
    input_400 = self.n_Conv_188(input_396)
    onnx__Conv_1717 = F.elu(input_400)
    input_404 = self.n_Conv_190(onnx__Conv_1717)
    onnx__Conv_1724 = F.elu(input_404)
    onnx__Add_2280 = self.n_Conv_192(onnx__Conv_1724)
    input_408 = torch.add(onnx__Add_2280, input_396)
    input_412 = self.n_Conv_194(input_408)
    onnx__Conv_1738 = F.elu(input_412)
    input_416 = self.n_Conv_196(onnx__Conv_1738)
    onnx__Conv_1745 = F.elu(input_416)
    input_420 = self.n_Conv_198(onnx__Conv_1745)
    input_424 = self.n_Conv_199(input_420)
    onnx__Conv_1758 = F.elu(input_424)
    input_428 = self.n_Conv_201(onnx__Conv_1758)
    onnx__Conv_1765 = F.elu(input_428)
    onnx__Add_2298 = self.n_Conv_203(onnx__Conv_1765)
    input_432 = torch.add(onnx__Add_2298, input_420)
    input_436 = self.n_Conv_205(input_432)
    onnx__Conv_1779 = F.elu(input_436)
    input_440 = self.n_Conv_207(onnx__Conv_1779)
    onnx__Conv_1786 = F.elu(input_440)
    onnx__Add_2307 = self.n_Conv_209(onnx__Conv_1786)
    input_444 = torch.add(onnx__Add_2307, input_432)
    input_448 = self.n_Conv_211(input_444)
    onnx__Conv_1800 = F.elu(input_448)
    input_452 = self.n_Conv_213(onnx__Conv_1800)
    onnx__Conv_1807 = F.elu(input_452)
    onnx__Add_2316 = self.n_Conv_215(onnx__Conv_1807)
    input_456 = torch.add(onnx__Add_2316, input_444)
    input_460 = self.n_Conv_217(input_456)
    onnx__Conv_1821 = F.elu(input_460)
    input_464 = self.n_Conv_219(onnx__Conv_1821)
    onnx__Conv_1828 = F.elu(input_464)
    input_468 = self.n_Conv_221(onnx__Conv_1828)
    input_472 = self.n_Conv_222(input_468)
    onnx__Conv_1841 = F.elu(input_472)
    onnx__Flatten_2331 = self.n_Conv_224(onnx__Conv_1841)
    input_476 = self.n_Flatten_225(onnx__Flatten_2331)
    onnx__Gemm_1849 = torch.cat((input_276, input_476), **{'dim': 1})
    input_480 = 1.0 * torch.matmul(onnx__Gemm_1849, torch.transpose(self._vars["supercombo_policy_summarizer__infeats_0_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_summarizer__infeats_0_bias"]
    onnx__Gemm_1851 = F.relu(input_480)
    input_484 = 1.0 * torch.matmul(onnx__Gemm_1851, torch.transpose(self._vars["supercombo_policy_hydra_in_layer_meta_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_in_layer_meta_bias"]
    onnx__Gemm_1853 = F.relu(input_484)
    input_488 = 1.0 * torch.matmul(onnx__Gemm_1851, torch.transpose(self._vars["supercombo_policy_hydra_in_layer_desire_pred_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_in_layer_desire_pred_bias"]
    onnx__Gemm_1855 = F.relu(input_488)
    input_492 = 1.0 * torch.matmul(onnx__Gemm_1851, torch.transpose(self._vars["supercombo_policy_hydra_in_layer_pose_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_in_layer_pose_bias"]
    onnx__Gemm_1857 = F.relu(input_492)
    input_496 = 1.0 * torch.matmul(onnx__Gemm_1853, torch.transpose(self._vars["supercombo_policy_hydra_res_layer_meta_0_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_res_layer_meta_0_bias"]
    onnx__Gemm_1859 = F.relu(input_496)
    onnx__Add_1860 = 1.0 * torch.matmul(onnx__Gemm_1859, torch.transpose(self._vars["supercombo_policy_hydra_res_layer_meta_2_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_res_layer_meta_2_bias"]
    input_500 = torch.add(onnx__Gemm_1853, onnx__Add_1860)
    onnx__Gemm_1862 = F.relu(input_500)
    input_504 = 1.0 * torch.matmul(onnx__Gemm_1855, torch.transpose(self._vars["supercombo_policy_hydra_res_layer_desire_pred_0_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_res_layer_desire_pred_0_bias"]
    onnx__Gemm_1864 = F.relu(input_504)
    onnx__Add_1865 = 1.0 * torch.matmul(onnx__Gemm_1864, torch.transpose(self._vars["supercombo_policy_hydra_res_layer_desire_pred_2_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_res_layer_desire_pred_2_bias"]
    input_508 = torch.add(onnx__Gemm_1855, onnx__Add_1865)
    onnx__Gemm_1867 = F.relu(input_508)
    input_512 = 1.0 * torch.matmul(onnx__Gemm_1857, torch.transpose(self._vars["supercombo_policy_hydra_res_layer_pose_0_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_res_layer_pose_0_bias"]
    onnx__Gemm_1869 = F.relu(input_512)
    onnx__Add_1870 = 1.0 * torch.matmul(onnx__Gemm_1869, torch.transpose(self._vars["supercombo_policy_hydra_res_layer_pose_2_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_res_layer_pose_2_bias"]
    input_516 = torch.add(onnx__Gemm_1857, onnx__Add_1870)
    onnx__Gemm_1872 = F.relu(input_516)
    onnx__Concat_1873 = 1.0 * torch.matmul(onnx__Gemm_1862, torch.transpose(self._vars["supercombo_policy_hydra_final_layer_meta_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_final_layer_meta_bias"]
    onnx__Concat_1874 = 1.0 * torch.matmul(onnx__Gemm_1867, torch.transpose(self._vars["supercombo_policy_hydra_final_layer_desire_pred_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_final_layer_desire_pred_bias"]
    onnx__Concat_1875 = 1.0 * torch.matmul(onnx__Gemm_1872, torch.transpose(self._vars["supercombo_policy_hydra_final_layer_pose_weight"], 0, 1)) + 1.0 * self._vars["supercombo_policy_hydra_final_layer_pose_bias"]
    input_520 = torch.cat((input_276, input_476, desire, traffic_convention), **{'dim': 1})
    onnx__Gemm_1877 = F.elu(input_520)
    input_524 = 1.0 * torch.matmul(onnx__Gemm_1877, torch.transpose(self._vars["temporal_policy_temporal_summarizer__infeats_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_summarizer__infeats_0_bias"]
    onnx__Gemm_1879 = F.relu(input_524)
    onnx__Split_1880 = 1.0 * torch.matmul(onnx__Gemm_1879, torch.transpose(self._vars["temporal_policy_temporal_summarizer__rnn_x2h_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_summarizer__rnn_x2h_bias"]
    onnx__Split_1881 = 1.0 * torch.matmul(initial_state, torch.transpose(self._vars["temporal_policy_temporal_summarizer__rnn_h2h_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_summarizer__rnn_h2h_bias"]
    onnx__Add_1882, onnx__Add_1883, onnx__Add_1884 = torch.split(onnx__Split_1880, **{'split_size_or_sections': [512, 512, 512], 'dim': 1})
    onnx__Add_1885, onnx__Add_1886, onnx__Mul_1887 = torch.split(onnx__Split_1881, **{'split_size_or_sections': [512, 512, 512], 'dim': 1})
    onnx__Sigmoid_1888 = torch.add(onnx__Add_1882, onnx__Add_1885)
    onnx__Mul_1889 = torch.sigmoid(onnx__Sigmoid_1888)
    onnx__Sigmoid_1890 = torch.add(onnx__Add_1883, onnx__Add_1886)
    onnx__Mul_1891 = torch.sigmoid(onnx__Sigmoid_1890)
    onnx__Add_1892 = torch.mul(onnx__Mul_1889, onnx__Mul_1887)
    onnx__Tanh_1893 = torch.add(onnx__Add_1884, onnx__Add_1892)
    onnx__Sub_1894 = torch.tanh(onnx__Tanh_1893)
    onnx__Mul_1895 = torch.sub(initial_state, onnx__Sub_1894)
    onnx__Add_1896 = torch.mul(onnx__Mul_1891, onnx__Mul_1895)
    onnx__Concat_1897 = torch.add(onnx__Sub_1894, onnx__Add_1896)
    onnx__Gemm_1898 = torch.cat((onnx__Concat_1897, onnx__Gemm_1879), **{'dim': 1})
    input_528 = 1.0 * torch.matmul(onnx__Gemm_1898, torch.transpose(self._vars["temporal_policy_temporal_summarizer__outfeats_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_summarizer__outfeats_0_bias"]
    onnx__Gemm_1900 = F.relu(input_528)
    input_532 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_plan_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_plan_bias"]
    onnx__Gemm_1902 = F.relu(input_532)
    input_536 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_lead_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_lead_bias"]
    onnx__Gemm_1904 = F.relu(input_536)
    input_540 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_lead_prob_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_lead_prob_bias"]
    onnx__Gemm_1906 = F.relu(input_540)
    input_544 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_lane_lines_prob_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_lane_lines_prob_bias"]
    onnx__Gemm_1908 = F.relu(input_544)
    input_548 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_stop_lines_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_stop_lines_bias"]
    onnx__Gemm_1910 = F.relu(input_548)
    input_552 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_stop_lines_prob_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_stop_lines_prob_bias"]
    onnx__Gemm_1912 = F.relu(input_552)
    input_556 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_road_edges_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_road_edges_bias"]
    onnx__Gemm_1914 = F.relu(input_556)
    input_560 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_lane_lines_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_lane_lines_bias"]
    onnx__Gemm_1916 = F.relu(input_560)
    input_564 = 1.0 * torch.matmul(onnx__Gemm_1900, torch.transpose(self._vars["temporal_policy_temporal_hydra_in_layer_desire_state_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_in_layer_desire_state_bias"]
    onnx__Gemm_1918 = F.relu(input_564)
    input_568 = 1.0 * torch.matmul(onnx__Gemm_1902, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_plan_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_plan_0_bias"]
    onnx__Gemm_1920 = F.relu(input_568)
    onnx__Add_1921 = 1.0 * torch.matmul(onnx__Gemm_1920, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_plan_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_plan_2_bias"]
    input_572 = torch.add(onnx__Gemm_1902, onnx__Add_1921)
    onnx__Gemm_1923 = F.relu(input_572)
    input_576 = 1.0 * torch.matmul(onnx__Gemm_1904, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lead_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lead_0_bias"]
    onnx__Gemm_1925 = F.relu(input_576)
    onnx__Add_1926 = 1.0 * torch.matmul(onnx__Gemm_1925, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lead_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lead_2_bias"]
    input_580 = torch.add(onnx__Gemm_1904, onnx__Add_1926)
    onnx__Gemm_1928 = F.relu(input_580)
    input_584 = 1.0 * torch.matmul(onnx__Gemm_1906, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lead_prob_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lead_prob_0_bias"]
    onnx__Gemm_1930 = F.relu(input_584)
    onnx__Add_1931 = 1.0 * torch.matmul(onnx__Gemm_1930, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lead_prob_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lead_prob_2_bias"]
    input_588 = torch.add(onnx__Gemm_1906, onnx__Add_1931)
    onnx__Gemm_1933 = F.relu(input_588)
    input_592 = 1.0 * torch.matmul(onnx__Gemm_1908, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_prob_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_prob_0_bias"]
    onnx__Gemm_1935 = F.relu(input_592)
    onnx__Add_1936 = 1.0 * torch.matmul(onnx__Gemm_1935, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_prob_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_prob_2_bias"]
    input_596 = torch.add(onnx__Gemm_1908, onnx__Add_1936)
    onnx__Gemm_1938 = F.relu(input_596)
    input_600 = 1.0 * torch.matmul(onnx__Gemm_1910, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_0_bias"]
    onnx__Gemm_1940 = F.relu(input_600)
    onnx__Add_1941 = 1.0 * torch.matmul(onnx__Gemm_1940, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_2_bias"]
    input_604 = torch.add(onnx__Gemm_1910, onnx__Add_1941)
    onnx__Gemm_1943 = F.relu(input_604)
    input_608 = 1.0 * torch.matmul(onnx__Gemm_1912, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_prob_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_prob_0_bias"]
    onnx__Gemm_1945 = F.relu(input_608)
    onnx__Add_1946 = 1.0 * torch.matmul(onnx__Gemm_1945, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_prob_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_stop_lines_prob_2_bias"]
    input_612 = torch.add(onnx__Gemm_1912, onnx__Add_1946)
    onnx__Gemm_1948 = F.relu(input_612)
    input_616 = 1.0 * torch.matmul(onnx__Gemm_1914, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_road_edges_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_road_edges_0_bias"]
    onnx__Gemm_1950 = F.relu(input_616)
    onnx__Add_1951 = 1.0 * torch.matmul(onnx__Gemm_1950, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_road_edges_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_road_edges_2_bias"]
    input_620 = torch.add(onnx__Gemm_1914, onnx__Add_1951)
    onnx__Gemm_1953 = F.relu(input_620)
    input_624 = 1.0 * torch.matmul(onnx__Gemm_1916, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_0_bias"]
    onnx__Gemm_1955 = F.relu(input_624)
    onnx__Add_1956 = 1.0 * torch.matmul(onnx__Gemm_1955, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_lane_lines_2_bias"]
    input_628 = torch.add(onnx__Gemm_1916, onnx__Add_1956)
    onnx__Gemm_1958 = F.relu(input_628)
    input_632 = 1.0 * torch.matmul(onnx__Gemm_1918, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_desire_state_0_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_desire_state_0_bias"]
    onnx__Gemm_1960 = F.relu(input_632)
    onnx__Add_1961 = 1.0 * torch.matmul(onnx__Gemm_1960, torch.transpose(self._vars["temporal_policy_temporal_hydra_res_layer_desire_state_2_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_res_layer_desire_state_2_bias"]
    input_636 = torch.add(onnx__Gemm_1918, onnx__Add_1961)
    onnx__Gemm_1963 = F.relu(input_636)
    onnx__Concat_1964 = 1.0 * torch.matmul(onnx__Gemm_1923, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_plan_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_plan_bias"]
    onnx__Concat_1965 = 1.0 * torch.matmul(onnx__Gemm_1928, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_lead_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_lead_bias"]
    onnx__Concat_1966 = 1.0 * torch.matmul(onnx__Gemm_1933, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_lead_prob_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_lead_prob_bias"]
    onnx__Concat_1967 = 1.0 * torch.matmul(onnx__Gemm_1938, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_lane_lines_prob_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_lane_lines_prob_bias"]
    onnx__Concat_1968 = 1.0 * torch.matmul(onnx__Gemm_1943, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_stop_lines_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_stop_lines_bias"]
    onnx__Concat_1969 = 1.0 * torch.matmul(onnx__Gemm_1948, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_stop_lines_prob_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_stop_lines_prob_bias"]
    onnx__Concat_1970 = 1.0 * torch.matmul(onnx__Gemm_1953, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_road_edges_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_road_edges_bias"]
    onnx__Concat_1971 = 1.0 * torch.matmul(onnx__Gemm_1958, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_lane_lines_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_lane_lines_bias"]
    onnx__Concat_1972 = 1.0 * torch.matmul(onnx__Gemm_1963, torch.transpose(self._vars["temporal_policy_temporal_hydra_final_layer_desire_state_weight"], 0, 1)) + 1.0 * self._vars["temporal_policy_temporal_hydra_final_layer_desire_state_bias"]
    outputs = torch.cat((onnx__Concat_1964, onnx__Concat_1971, onnx__Concat_1967, onnx__Concat_1970, onnx__Concat_1965, onnx__Concat_1966, onnx__Concat_1968, onnx__Concat_1969, onnx__Concat_1972, onnx__Concat_1873, onnx__Concat_1874, onnx__Concat_1875, onnx__Concat_1897), **{'dim': 1})
    return outputs

  def compatible_auto_pad(self, input, kernel_spatial_shape, nn_mod, auto_pad=None, **kwargs):
    input_spatial_shape = input.shape[2:]
    d = len(input_spatial_shape)
    strides = nn_mod.stride
    dilations = nn_mod.dilation
    output_spatial_shape = [math.ceil(float(l) / float(r)) for l, r in zip(input.shape[2:], strides)]
    pt_padding = [0] * 2 * d
    pad_shape = [0] * d
    for i in range(d):
      pad_shape[i] = (output_spatial_shape[i] - 1) * strides[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]
      mean = pad_shape[i] // 2
      if auto_pad == b"SAME_UPPER":
        l, r = pad_shape[i] - mean, mean
      else:
        l, r = mean, pad_shape[i] - mean
      pt_padding.insert(0, r)
      pt_padding.insert(0, l)
    return F.pad(input, pt_padding)

@torch.no_grad()
def test_run_model(inputs=[torch.from_numpy(np.random.randn(*[1, 12, 128, 256]).astype(np.float32)), torch.from_numpy(np.random.randn(*[1, 12, 128, 256]).astype(np.float32)), torch.from_numpy(np.random.randn(*[1, 8]).astype(np.float32)), torch.from_numpy(np.random.randn(*[1, 2]).astype(np.float32)), torch.from_numpy(np.random.randn(*[1, 512]).astype(np.float32))]):
  model = Model()
  model.eval()
  rs = model(*inputs)
  print(rs)
  return rs
