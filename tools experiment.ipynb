{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import onnx\n",
    "from easydict import EasyDict\n",
    "\n",
    "from onnx2keras import onnx_to_keras\n",
    "from onnx_pytorch import code_gen\n",
    "\n",
    "\n",
    "from adversarialbox.adversary import Adversary\n",
    "from adversarialbox.attacks.gradient_method import FGSM\n",
    "from advbox.models.keras import KerasModel\n",
    "from tutorials.mnist_model_pytorch import Net\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from pytorchGenerator.model import Model\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import eagerpy as ep\n",
    "\n",
    "from foolbox import PyTorchModel, accuracy, samples\n",
    "from foolbox.attacks import LinfPGD\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification.keras import KerasClassifier\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.utils import load_mnist\n",
    "\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(input):\n",
    "    return 1 / (1 + np.exp(-input))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def onnx2Keras(path):\n",
    "    onnx_model = onnx.load(path)\n",
    "    model = onnx_to_keras(onnx_model, ['input_imgs', 'big_input_imgs', 'desire', 'traffic_convention', 'initial_state'],\n",
    "                          name_policy='renumerate', change_ordering=False)\n",
    "    model.save(\"models/keras\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ld_mnist():\n",
    "    \"\"\"Load training and test data.\"\"\"\n",
    "\n",
    "    def convert_types(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255\n",
    "        return image, label\n",
    "\n",
    "    dataset, info = tfds.load(\n",
    "        \"mnist\",  with_info=True, as_supervised=True\n",
    "    )\n",
    "    mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]\n",
    "    mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(128)\n",
    "    mnist_test = mnist_test.map(convert_types).batch(128)\n",
    "    return EasyDict(train=mnist_train, test=mnist_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "onnx_model = \"models/supercombo.onnx\"\n",
    "kerasModel = tf.keras.models.load_model(\"models/keras\", compile=False)\n",
    "pytorchModel = torch.load('models/supercombo.pt')\n",
    "pytorchModel.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
    "data = ld_mnist()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=4, kernel_size=(5, 5), strides=1, activation=\"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=10, kernel_size=(5, 5), strides=1, activation=\"relu\", input_shape=(23, 23, 4)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(learning_rate=0.01), metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = np.load('data/numpy.npz')\n",
    "\n",
    "datasize = dataset['inputImgs'].shape[0]\n",
    "\n",
    "inputImgs_data = dataset['inputImgs']\n",
    "bigInputImgs_data = dataset['bigInputImgs']\n",
    "desire_data = dataset['desire']\n",
    "trafficConvention_data = dataset['trafficConvention']\n",
    "initialState_data = dataset['initialState']\n",
    "output_data = dataset['output']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing tool –Adversial Robustness 360 Toolbox–"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    classifier = KerasClassifier(model=kerasModel, use_logits=False)\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "    x_test_adv = attack.generate(x={\"input_imgs\": inputImgs_data,\n",
    "                                    \"big_input_imgs\": bigInputImgs_data,\n",
    "                                    \"desire\": desire_data,\n",
    "                                    \"traffic_convention\": trafficConvention_data,\n",
    "                                    \"initial_state\": initialState_data})\n",
    "    predictions = classifier.predict(x_test_adv)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n",
    "except Exception as e: print(\"Expected 1 input variable but got 5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    classifier = KerasClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value), use_logits=False)\n",
    "    classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)\n",
    "    predictions = classifier.predict(x_test)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Clean Accuracy : {}%\".format(accuracy * 100))\n",
    "    attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
    "    x_test_adv = attack.generate(x=x_test)\n",
    "    predictions = classifier.predict(x_test_adv)\n",
    "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
    "    print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing tool –Cleverhans–"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    test_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
    "    test_acc_fgsm = tf.metrics.SparseCategoricalAccuracy()\n",
    "    for x, y in dataset:\n",
    "        test_acc_clean(y, output_data)\n",
    "        x_fgm = fast_gradient_method(kerasModel, x, 0.3, np.inf)\n",
    "        y_pred_fgm = model(x_fgm)\n",
    "        test_acc_fgsm(y, y_pred_fgm)\n",
    "\n",
    "    print(\"test acc on clean examples (%): {:.3f}\".format(test_acc_clean.result() * 100))\n",
    "    print(\"test acc on FGM adversarial examples (%): {:.3f}\".format(test_acc_fgsm.result() * 100))\n",
    "except Exception as e: print(\"Expected 1 input variable but got 5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    test_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
    "    test_acc_fgsm = tf.metrics.SparseCategoricalAccuracy()\n",
    "    for x, y in data.test:\n",
    "        y_pred = model(x)\n",
    "        test_acc_clean(y, y_pred)\n",
    "\n",
    "        x_fgm = fast_gradient_method(model, x, 0.3, np.inf)\n",
    "        y_pred_fgm = model(x_fgm)\n",
    "        test_acc_fgsm(y, y_pred_fgm)\n",
    "\n",
    "    print(\"test acc on clean examples (%): {:.3f}\".format(test_acc_clean.result() * 100))\n",
    "    print(\"test acc on FGM adversarial examples (%): {:.3f}\".format(test_acc_fgsm.result() * 100))\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing tool –Foolbox–"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Foolbox worked\")\n",
    "except Exception as e: print(\"Expected 1 input variable but got 5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    model = models.resnet18(pretrained=True).eval()\n",
    "    preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "\n",
    "    images, labels = ep.astensors(*samples(fmodel, dataset=\"imagenet\", batchsize=16))\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\n",
    "\n",
    "    attack = LinfPGD()\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "    print(\"robust accuracy for perturbations with\")\n",
    "    for eps, acc in zip(epsilons, robust_accuracy):\n",
    "        print(f\"  Linf norm ≤ {eps:<6}: {acc.item() * 100:4.1f} %\")\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing tool –AdvBox–"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"AdvBox worked\")\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    m = KerasModel(\n",
    "        model, loss_func,(0, 1),\n",
    "        channel_axis=1)\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing tool –Foolbox–"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Foolbox worked\")\n",
    "except Exception as e: print(\"Expected 1 input variable but got 5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    model = models.resnet18(pretrained=True).eval()\n",
    "    preprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "    fmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\n",
    "\n",
    "    images, labels = ep.astensors(*samples(fmodel, dataset=\"imagenet\", batchsize=16))\n",
    "    clean_acc = accuracy(fmodel, images, labels)\n",
    "    print(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\n",
    "\n",
    "    attack = LinfPGD()\n",
    "    epsilons = [\n",
    "        0.0,\n",
    "        0.0002,\n",
    "        0.0005,\n",
    "        0.0008,\n",
    "        0.001,\n",
    "        0.0015,\n",
    "        0.002,\n",
    "        0.003,\n",
    "        0.01,\n",
    "        0.1,\n",
    "        0.3,\n",
    "        0.5,\n",
    "        1.0,\n",
    "    ]\n",
    "    raw_advs, clipped_advs, success = attack(fmodel, images, labels, epsilons=epsilons)\n",
    "    robust_accuracy = 1 - success.float32().mean(axis=-1)\n",
    "    print(\"robust accuracy for perturbations with\")\n",
    "    for eps, acc in zip(epsilons, robust_accuracy):\n",
    "        print(f\"  Linf norm ≤ {eps:<6}: {acc.item() * 100:4.1f} %\")\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing tool –AdvBox–"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"AdvBox worked\")\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "    m = KerasModel(\n",
    "        model, loss_func,(0, 1),\n",
    "        channel_axis=1)\n",
    "except Exception as e: print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}